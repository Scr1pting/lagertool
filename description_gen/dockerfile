# Use a lightweight Python image
FROM python:3.12-slim

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    LLAMA_LOG_LEVEL=warn \
    NLTK_DATA=/root/nltk_data

# Set working directory
WORKDIR /app

# Copy requirements first (to leverage Docker cache)
COPY requirements.txt .

# Install system dependencies needed for llama-cpp-python
RUN apt-get update && apt-get install -y \
        build-essential \
        cmake \
        git \
        wget \
        curl \
        libopenblas-dev \
    && mkdir -p "$NLTK_DATA" \
    && pip install --upgrade pip setuptools wheel \
    && pip install -r requirements.txt \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

RUN python -m nltk.downloader wordnet

# Copy app code
COPY ./app ./app

# Expose FastAPI port
EXPOSE 8080

# Run the API
# CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
CMD ["python", "app/main.py"]
